SPAM ASSIN CASE STUDY

1. 
Welcome to our case study on spam. This week, we'll be dealing with an issue of a classifier. And our data is no longer contained in an ICE data frame or spreadsheet. An important part of this will be processing the data.
Follow along the video as you get more details about the problem. As always, see if you have the same or different questions as our protagonist about what's going on with the data and the details of the problem. This week, we'll be probably using some clustering. And you definitely want to use a naive base for your assignment.
Good luck and enjoy the video coming up. And remember, as always, to add your questions to your upload for your participation.

2. 
OK, so this week, we received a request from our IT department in that we as a company receive a significant amount of spam. So we've been given a collection of emails, both normal and spam, and our goal is that we need to process this data and then build a classifier that will classify emails as spam or not spam. So our goal for this week is to build a model that can take any given email and provide a classification. So essentially, what we're doing is we're building an email filter. And your task is to go through all of this data, process it, and then build, based on the contents of an email, a model that can predict whether any given email is spam or not spam. So that's your assignment. Are there any questions?

3. 
OK, so now that you've had a chance to look over the actual emails, are there any questions? Yeah, I actually have one overarching question. So what happens if we misclassify something as spam when it's not or vice versa? Would you rather us filter out too many spam messages and risk moving real emails to the Spam folder, or would you rather have a few spam messages make it through so that the real emails don't get lost?
Yeah, that's an excellent question. And, I mean, I leave that up to you. Obviously, nobody wants to lose an important email by having it go into the Spam folder, but we're losing important emails now because they're getting lost in the shuffle because of the sheer volume of spam. So really it's whatever you decide works best.
That's your call. OK, got it. So I do have actually one more question. I know I said I had one, but I have another one.
My other question is about the data set. Is there a spreadsheet or file of this data? Yeah. Unfortunately, there is not.
All we have are the emails themselves. So you are going to have to generate your own data set for this assignment. OK. But this is definitely something a little new for us.
Is there anything that's been done on spam filtering before that we can check out for this? I believe that in the past, people have used Naive Bayes as an email filter. And it's been quite successful. So I would look into that.
OK. Great.

Case Study 3.
Build a spam classifier using naive Bayes and clustering. You will have to create your own dataset from the input messages. Be sure to document how you created your dataset.

sample for captions: 
arxiv.org/pdf/2502.05078




Feedback from case study 2: 

Feb 10 at 7pm
Lets make sure we get actual tables for the classification report and confusion matrix (or use ConfusionMatrixDisplay.frompredictions()

Definitly need a wider value search for C, for instance I do 10E-6 to 10R+6 (20 values).

Reminder are results should be Cross Validated Results so your support should be 101k for this case study

- Robert Slater



I will continue in the first person and summarize the immediate steps I should take to finish Case Study 3 in alignment with the professor’s instructions, the class transcript, and the standard requirements:

1. Document my Data Prep Thoroughly.
   • I will describe how I read the raw email files, how I stripped headers, decoded quoted-printable text, and removed HTML.  
   • I will explain my imputation methods (if any are needed), why I chose them, and provide the size of my final dataset (the total number of examples/emails and the number of features after vectorization).
   • I will document which libraries I used for text cleaning, tokenization, removing stopwords, etc.

2. Build My Own Dataset.
   • Since only raw emails were provided, I will make sure I save a dataframe or table that includes each email’s text, its label (spam vs. ham), and possibly any additional metadata I extracted.
   • I will confirm how many spam emails vs. ham emails I have and handle imbalance if necessary (for instance with oversampling or generating synthetic spam).

3. Perform Naive Bayes Classification with Cross-Validation (No Train/Test Split).
   • I will not finalize my results by doing a single train/test split. Instead, I will do K-fold (or StratifiedKFold) cross-validation on the entire dataset to measure performance. 
   • I will systematically vary the hyperparameters (e.g., alpha for Naive Bayes) over a wide range, such as 10^-6 up to 10^6 in a log scale (the “20 values” approach).
   • I will then pick the best hyperparameter(s) and report the cross-validation results.

4. Show a Confusion Matrix and Classification Metrics for All Examples.
   • Once I have my final model, I will produce a confusion matrix for the entire dataset (using cross-validation predictions or final model predictions).
   • I will provide a classification report: precision, recall, F1-score, and also compute the AUC-ROC since it is a binary classification problem.
   • I should show these metrics clearly in a table, or by using ConfusionMatrixDisplay.from_predictions, so it’s easy to see how many were misclassified.

5. Incorporate Clustering in the Analysis.
   • I will do some clustering (for example, K-means) on the TF-IDF vectors to see if spam and ham form distinct clusters.  
   • I could explore whether adding cluster labels as features helps or just use clustering for insight.

6. Present Results with More Detail.
   • Instead of saying “it performed well,” I will be specific: “The 5-fold cross-validation accuracy is X, precision is Y, recall is Z, etc.” 
   • I will not call it “impressive” or “good.” I will simply present the actual numeric results.

7. Provide Figures with Captions/Explanations.
   • Since the professor wants more descriptive figures, I will add captions or textual explanations. For instance, “Figure 1 shows the confusion matrix for the final model predictions across all folds” or “Table 2 displays the classification report including precision, recall, F1-score, and support for each class.”

8. Repeat the Professor’s Key Feedback.
   • I will avoid statements like “trained well” or “performed well.” Instead, I will show numerical performance.  
   • I will ensure cross-validation is done for the final results (no single train/test split).
   • I will do a wide parameter search for alpha (and I can do more for other parameters if I want an ablation study).  
   • I will present the final best hyperparameters and the results across the entire dataset.

By doing each of these, I will fully address the requirements for Case Study 3, including the feedback from the last class meeting.